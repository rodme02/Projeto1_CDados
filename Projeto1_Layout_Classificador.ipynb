{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: _____\n",
    "\n",
    "Nome: _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "/Users/rodrigomedeiros/Documents/Insper/2_semestre/CienciaDosDados/Projeto1_CDados\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'vacina.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@borboletadirceu as gr√°vidas podem tomar vacin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>com todo respeito, uma decis√£o quebra a fila √∫...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>minha tia tava falando q n√£o ia tomar vacina (...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adivinha, com lockdown e vacina https://t.co/f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@revistaoeste olha as ideia... o povo achando ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classifica√ß√£o\n",
       "0  @borboletadirceu as gr√°vidas podem tomar vacin...              1\n",
       "1  com todo respeito, uma decis√£o quebra a fila √∫...              0\n",
       "2  minha tia tava falando q n√£o ia tomar vacina (...              0\n",
       "3  adivinha, com lockdown e vacina https://t.co/f...              0\n",
       "4  @revistaoeste olha as ideia... o povo achando ...              1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename, sheet_name = 'Treinamento')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@drunkclurichaun @folha o governo n√£o compra p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@mrnamelesszero @gentedemal a vacina √© igual p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@fiscaldoibama o judici√°rio ainda vai pedir au...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eu depois da vacina. https://t.co/vnoryzfqjy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m√™s q vem j√° tenho vacina pra toma dnv üòÇü§¶üèª‚Äç‚ôÄÔ∏è ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica√ß√£o\n",
       "0  @drunkclurichaun @folha o governo n√£o compra p...              1\n",
       "1  @mrnamelesszero @gentedemal a vacina √© igual p...              1\n",
       "2  @fiscaldoibama o judici√°rio ainda vai pedir au...              0\n",
       "3       eu depois da vacina. https://t.co/vnoryzfqjy              0\n",
       "4  m√™s q vem j√° tenho vacina pra toma dnv üòÇü§¶üèª‚Äç‚ôÄÔ∏è ...              0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Classifica√ß√£o']= train[\"Classifica√ß√£o\"].astype(str)\n",
    "\n",
    "Relevante = train.loc[(train.Classifica√ß√£o=='1')]\n",
    "Irrelevante = train.loc[(train.Classifica√ß√£o=='0')]\n",
    "\n",
    "Relevantes = ''.join(Relevante.Treinamento)\n",
    "Irrelevantes = ''.join(Irrelevante.Treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpando as strings\n",
    "\n",
    "\n",
    "def cleanup1(text):\n",
    "    \n",
    "    \"Troca sinais e links por espa√ßos\"\n",
    "    \n",
    "    text = re.sub(r'@\\S+', ' ', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'_', ' ', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\n', ' ', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'kk\\S+', ' ', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'http\\S+', ' ', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'https\\S+', ' ', text, flags=re.MULTILINE)\n",
    "    punctuation = '[!-.:?;_‚Äú‚Äù]'\n",
    "\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed\n",
    "\n",
    "emoji_pat = '[\\U0001F300-\\U0001F64F\\U0001F680-\\U0001F6FF\\u2600-\\u26FF\\u2700-\\u27BF]'\n",
    "shrink_whitespace_reg = re.compile(r'\\s{2,}')\n",
    "\n",
    "\n",
    "def cleanup2(text_subbed):\n",
    "    \n",
    "    \"Tira Espa√ßos em excesso e separa emojis com espa√ßos\"\n",
    "    \n",
    "    reg = re.compile(r'({})'.format(emoji_pat))\n",
    "    result = reg.sub(lambda x: ' {} '.format(x.group(1)) if x.group(1) else ' ', text_subbed)\n",
    "    return shrink_whitespace_reg.sub(' ', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Relevantes_clean = cleanup1(Relevantes)\n",
    "Relevantes_clean = cleanup2(Relevantes_clean)\n",
    "\n",
    "Irrelevantes_clean = cleanup1(Irrelevantes)\n",
    "Irrelevantes_clean = cleanup2(Irrelevantes_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de palavras relevantes:\n",
      "2538\n",
      "\n",
      "\n",
      "N√∫mero de palavras irrelevantes:\n",
      "2336\n"
     ]
    }
   ],
   "source": [
    "Palavras_relevantes = pd.Series(Relevantes_clean.split())\n",
    "\n",
    "\n",
    "Palavras_irrelevantes = pd.Series(Irrelevantes_clean.split())\n",
    "\n",
    "print('N√∫mero de palavras relevantes:')\n",
    "print(len(Palavras_relevantes))\n",
    "print('\\n')\n",
    "print('N√∫mero de palavras irrelevantes:')\n",
    "print(len(Palavras_irrelevantes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_total_palavras = []\n",
    "\n",
    "for x in Palavras_relevantes:\n",
    "    lista_total_palavras.append(x)\n",
    "    \n",
    "for y in Palavras_irrelevantes:\n",
    "    lista_total_palavras.append(y)\n",
    "\n",
    "total_palavras_n_repitir = pd.Series(lista_total_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1620"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_lista_absoluta = total_palavras_n_repitir.value_counts(ascending=False)\n",
    "\n",
    "len(total_lista_absoluta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vacina    99\n",
       "de        94\n",
       "a         86\n",
       "o         65\n",
       "n√£o       64\n",
       "          ..\n",
       "doente     1\n",
       "m√£o        1\n",
       "fica       1\n",
       "d          1\n",
       "num        1\n",
       "Length: 959, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_absoluta_relevantes = Palavras_relevantes.value_counts(ascending=False)\n",
    "\n",
    "\n",
    "tabela_absoluta_relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vacina      114\n",
       "a            97\n",
       "de           73\n",
       "que          57\n",
       "e            56\n",
       "           ... \n",
       "g√™nio         1\n",
       "grande        1\n",
       "acaso         1\n",
       "judicial      1\n",
       "levar         1\n",
       "Length: 975, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_absoluta_irrelevantes = Palavras_irrelevantes.value_counts(ascending=False)\n",
    "\n",
    "\n",
    "tabela_absoluta_irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_relativa_relevantes = Palavras_relevantes.value_counts(True)\n",
    "tabela_relativa_relevantes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_relativa_irrelevantes = Palavras_irrelevantes.value_counts(True)\n",
    "tabela_relativa_irrelevantes.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "O produto escolhido foi \"vacina\", tomei como relevantes os tweets que se posicionam a favor ou contra da vacina e como irrelevantes os que n√£o demonstram um posicionamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5207221994255232\n",
      "0.47927780057447683\n"
     ]
    }
   ],
   "source": [
    "# total de palavras\n",
    "total = len(Palavras_relevantes) + len(Palavras_irrelevantes)\n",
    "\n",
    "# Probabilidade de ser relevantes:\n",
    "total_relevantes = len(Palavras_relevantes)/total\n",
    "\n",
    "# Probabilidade de ser irrelevantes:\n",
    "total_irrelevantes = len(Palavras_irrelevantes)/total\n",
    "\n",
    "#total de palavras sem repitir\n",
    "total_lista_absoluta\n",
    "\n",
    "print(total_relevantes)\n",
    "print(total_irrelevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = []\n",
    "\n",
    "for tweet in test.Teste:\n",
    "    y = cleanup1(tweet.lower())\n",
    "    tweets = cleanup2(y)\n",
    "    r = 1\n",
    "    i = 1\n",
    " \n",
    "    for x in tweets:\n",
    "        \n",
    "        if x not in tabela_absoluta_relevantes:\n",
    "            r = r * (0 + 1)/(len(Palavras_relevantes) + len(total_lista_absoluta))\n",
    "        else:\n",
    "            r = r *  (tabela_absoluta_relevantes[x] + 1)/(len(Palavras_relevantes) + len(total_lista_absoluta))\n",
    "        if x not in tabela_absoluta_irrelevantes:\n",
    "            i = i * (0 + 1)/(len(Palavras_irrelevantes) + len(total_lista_absoluta))\n",
    "        else:\n",
    "            i = i * (tabela_absoluta_irrelevantes[x] + 1)/(len(Palavras_irrelevantes) + len(total_lista_absoluta)) \n",
    "            \n",
    "    R = total_relevantes * r \n",
    "    I = total_irrelevantes * i \n",
    "    \n",
    "    \n",
    "    if I > R:\n",
    "        classificador.append(\"Irrelevante\")\n",
    "    else: \n",
    "        classificador.append(\"Relevante\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th>Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@drunkclurichaun @folha o governo n√£o compra p...</td>\n",
       "      <td>1</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@mrnamelesszero @gentedemal a vacina √© igual p...</td>\n",
       "      <td>1</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@fiscaldoibama o judici√°rio ainda vai pedir au...</td>\n",
       "      <td>0</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eu depois da vacina. https://t.co/vnoryzfqjy</td>\n",
       "      <td>0</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m√™s q vem j√° tenho vacina pra toma dnv üòÇü§¶üèª‚Äç‚ôÄÔ∏è ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>resumo do dia: bolsotario dizendo as suas ment...</td>\n",
       "      <td>0</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>@claudemirsl @biakicis nossa, voc√™ perdeu a ed...</td>\n",
       "      <td>0</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>no brasil, mais de 10 milh√µes de pessoas se cu...</td>\n",
       "      <td>1</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>o juiz ao entender inconstitucionalidade na le...</td>\n",
       "      <td>1</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>ah cansei .. nao tem vacina, os cmaluco vao co...</td>\n",
       "      <td>0</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Classifica√ß√£o  \\\n",
       "0    @drunkclurichaun @folha o governo n√£o compra p...              1   \n",
       "1    @mrnamelesszero @gentedemal a vacina √© igual p...              1   \n",
       "2    @fiscaldoibama o judici√°rio ainda vai pedir au...              0   \n",
       "3         eu depois da vacina. https://t.co/vnoryzfqjy              0   \n",
       "4    m√™s q vem j√° tenho vacina pra toma dnv üòÇü§¶üèª‚Äç‚ôÄÔ∏è ...              0   \n",
       "..                                                 ...            ...   \n",
       "195  resumo do dia: bolsotario dizendo as suas ment...              0   \n",
       "196  @claudemirsl @biakicis nossa, voc√™ perdeu a ed...              0   \n",
       "197  no brasil, mais de 10 milh√µes de pessoas se cu...              1   \n",
       "198  o juiz ao entender inconstitucionalidade na le...              1   \n",
       "199  ah cansei .. nao tem vacina, os cmaluco vao co...              0   \n",
       "\n",
       "    Classificador  \n",
       "0     Irrelevante  \n",
       "1       Relevante  \n",
       "2     Irrelevante  \n",
       "3     Irrelevante  \n",
       "4     Irrelevante  \n",
       "..            ...  \n",
       "195     Relevante  \n",
       "196     Relevante  \n",
       "197     Relevante  \n",
       "198     Relevante  \n",
       "199     Relevante  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Classificador'] = classificador\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classificador</th>\n",
       "      <th>Irrelevante</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.2857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3295</td>\n",
       "      <td>0.7143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classificador  Irrelevante  Relevante\n",
       "Classifica√ß√£o                        \n",
       "0                   0.6705     0.2857\n",
       "1                   0.3295     0.7143"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test['Classifica√ß√£o'], test['Classificador'], normalize='columns').round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdadeiro positivo: 71.43%\n",
      "Falso positivo: 32.95%\n",
      "Verdadeiros negativos: 67.05%\n",
      "Falsos negativos: 28.57%\n",
      "\n",
      "Acertos: 69.24%\n",
      "Erros: 30.76%\n"
     ]
    }
   ],
   "source": [
    "acertos = (.7143 + .6705)/2\n",
    "erros = (.3295 + .2857)/2\n",
    "\n",
    "print(\"Verdadeiro positivo: 71.43%\")\n",
    "print(\"Falso positivo: 32.95%\")\n",
    "print(\"Verdadeiros negativos: 67.05%\")\n",
    "print(\"Falsos negativos: 28.57%\")\n",
    "print('')\n",
    "print(\"Acertos: {:.2%}\".format(acertos))\n",
    "print(\"Erros: {:.2%}\".format(erros))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√â poss√≠vel concluir que o classificador est√° funcionando corretamente, pois, como mostrado acima, tivemos 69.24% de acertos, por√©m os tweets com dupla nega√ß√£o e sarcasmo acabam n√£o sendo interpretados da forma que deveriam ser porque o classificador n√£o leva em conta a frase na qual as palavras est√£o.\n",
    "O plano de expans√£o √© levar em considera√ß√£o dupla nega√ß√£o e sarcasmo fazendo com que o classificar n√£o olhe somente as palavras individualmente mas tamb√©m as frases que elas comp√µem. Al√©m disso √© poss√≠vel aumentar o n√∫mero de grupos de classifica√ß√£o, como por exemplo muito relevantes e muito irrelevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test['Classificador']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['tweet'] = test['Teste']\n",
    "train['tweet'] = train['Treinamento']\n",
    "\n",
    "del test['Teste']\n",
    "del train['Treinamento']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de palavras relevantes:\n",
      "1\n",
      "\n",
      "\n",
      "N√∫mero de palavras irrelevantes:\n",
      "1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e73a43d55134>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mclassificador\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Relevante\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mteste\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Classificador'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassificador\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mverdadeiro_positivo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mteste\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteste\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2937\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2938\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3000\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3001\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3635\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3636\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3637\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3638\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Length of values does not match length of index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "todos_tweets = pd.concat([test, train])\n",
    "\n",
    "rows_teste = round((200/500) * len(todos_tweets))\n",
    "rows_treinamento = round(len(todos_tweets) - rows_teste)\n",
    "\n",
    "indx = 0\n",
    "\n",
    "for i in range (100):\n",
    "    \n",
    "    if indx == 1:\n",
    "        del teste\n",
    "        del treinamento\n",
    "    \n",
    "    teste = pd.DataFrame()\n",
    "    treinamento = pd.DataFrame()\n",
    "    \n",
    "    transfer_teste = todos_tweets.iloc[- rows_teste:, 0:]\n",
    "    teste = teste.append(transfer_teste)\n",
    "    transfer_treinamento = todos_tweets.iloc[rows_treinamento:, 0:]\n",
    "    treinamento = teste.append(transfer_treinamento)\n",
    "    \n",
    "    Relevante = treinamento.loc[(treinamento.Classifica√ß√£o=='1')]\n",
    "    Irrelevante = treinamento.loc[(treinamento.Classifica√ß√£o=='0')]\n",
    "\n",
    "    Relevantes = ''.join(Relevante)\n",
    "    Irrelevantes = ''.join(Irrelevante)\n",
    "\n",
    "    Relevantes_clean = cleanup1(Relevantes)\n",
    "    Relevantes_clean = cleanup2(Relevantes_clean)\n",
    "\n",
    "    Irrelevantes_clean = cleanup1(Irrelevantes)\n",
    "    Irrelevantes_clean = cleanup2(Irrelevantes_clean)\n",
    "\n",
    "    Palavras_relevantes = pd.Series(Relevantes_clean.split())\n",
    "    Palavras_irrelevantes = pd.Series(Irrelevantes_clean.split())\n",
    "    \n",
    "    total = len(Palavras_relevantes) + len(Palavras_irrelevantes)\n",
    "    total_relevantes = len(Palavras_relevantes)/total\n",
    "    total_irrelevantes = len(Palavras_irrelevantes)/total\n",
    "    \n",
    "    lista_total_palavras = []\n",
    "\n",
    "    for x in Palavras_relevantes:\n",
    "        lista_total_palavras.append(x)\n",
    "    \n",
    "    for y in Palavras_irrelevantes:\n",
    "        lista_total_palavras.append(y)\n",
    "\n",
    "    total_palavras_n_repitir = pd.Series(lista_total_palavras)\n",
    "    total_lista_absoluta = total_palavras_n_repitir.value_counts(ascending=False)\n",
    "    \n",
    "    classificador = []\n",
    "\n",
    "    for tweet in teste.tweet:\n",
    "        y = cleanup1(tweet.lower())\n",
    "        tweets = cleanup2(y)\n",
    "        r = 1\n",
    "        i = 1\n",
    " \n",
    "    for x in tweets:\n",
    "        \n",
    "        if x not in tabela_absoluta_relevantes:\n",
    "            r = r * (0 + 1)/(len(Palavras_relevantes) + len(total_lista_absoluta))\n",
    "        else:\n",
    "            r = r *  (tabela_absoluta_relevantes[x] + 1)/(len(Palavras_relevantes) + len(total_lista_absoluta))\n",
    "        if x not in tabela_absoluta_irrelevantes:\n",
    "            i = i * (0 + 1)/(len(Palavras_irrelevantes) + len(total_lista_absoluta))\n",
    "        else:\n",
    "            i = i * (tabela_absoluta_irrelevantes[x] + 1)/(len(Palavras_irrelevantes) + len(total_lista_absoluta)) \n",
    "            \n",
    "    R = total_relevantes * r \n",
    "    I = total_irrelevantes * i \n",
    "    \n",
    "    \n",
    "    if I > R:\n",
    "        classificador.append(\"Irrelevante\")\n",
    "    else: \n",
    "        classificador.append(\"Relevante\")\n",
    "\n",
    "    counter_classificador = Counter()\n",
    "    verdadeiro_positivo = (1, d(1))/(1, d(1))\n",
    "    \n",
    "    indx = 1\n",
    "    \n",
    "    teste['Classificador'] = classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
